{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调度专业知识问答系统\n",
    "## 集训前期提供过调度知识和人工智能的相关题库，每一个问题在excel中可找到相应的答案，即每一个样本数据是 <问题，答案>。 系统的核心思想是根据文本相似度，当用户输入一个问题，从题库中找到最相似的若干题目，然后直接返回相应的答案即可。\n",
    "### 考题1-6\n",
    "#### 1.定义删除母,数字，汉字以外的所有符号的函数remove_punctuation（），补充相关代码。（10分）\n",
    "#### 2.读取文本数据后，采用正则化方法，调用stopwords（）和remove_punctuation（），补充相关代码。（10分）\n",
    "#### 3.建立R行C列的矩阵TfIdf和OneHot，对应存放tfidf向量表示和01向量表示，R为文档样本数，这里是行数，C为不重复词语数，即编码维度，补充相关代码。（30分）\n",
    "#### 4.给定用户问题的单词列表query，通过向量表示Vector和词表words_vocab生成用户问题的向量表示vector_query，补充相关代码。（10分）\n",
    "#### 5.采用余弦相似度、欧式距离和曼哈顿距离计算句子间相似度，补充相关代码。（15分）\n",
    "#### 6.#使用函数cosine_similarity求出与用户问题最相似的问题，排序输出和用户问题相似度最高的前3个问题的答案，补充相关代码。（25分）\n",
    "    注意：这里我们采用TfIdf的向量表示，\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jieba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c8a8242f36b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mjieba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jieba'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采用正则化方法，定义删除除字母,数字，汉字以外的所有符号的函数\n",
    "def remove_punctuation(line):\n",
    "    line = str(line)\n",
    "    #######***************************答题区1***************************#######\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #######************************************************************#######\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#答题1测试\n",
    "line_test=\"《电力监控系统---安全防护123规定》中规定ab什么是 电力调度数`据网络？\"\n",
    "remove_punctuation(line_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取停用词，形成停用词表，类型为list\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取文本数据和停用词文件,采用正则化处理去除文本符号，并去停用词\n",
    "def read_file(filenane):\n",
    "    #######***************************答题区2***************************#######\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #######************************************************************#######\n",
    "    return file_txt,stopwords\n",
    "\n",
    "xls = '电力调度问答.xlsx'\n",
    "file_txt,stopwords = read_file(xls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理file_txt表格中的数据\n",
    "def build_corpus(file_txt):\n",
    "    file_txt['cut_review'] = file_txt['clean_review'].apply(lambda x: [w for w in list(jieba.cut(x)) if w not in stopwords and len(w) > 1])\n",
    "    return file_txt\n",
    "corpus = build_corpus(file_txt)\n",
    "print((\"file_txt['cut_review']:\\n\",corpus['cut_review'].values[0:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建TFIDF向量表示和哦OneHot向量表示\n",
    "def build_tfidf(corpus):\n",
    "    words_vocab =[]#存放不重复词语的列表\n",
    "    \n",
    "    #建立R行C列的矩阵TfIdf和OneHot存放tfidf向量表示和01向量表示，R为文档样本数，这里是行数，C为不重复词语数，即编码维度\n",
    "    #######***************************答题区3***************************#######\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #######************************************************************#######\n",
    "    TfIdf=pd.DataFrame(TfIdf,columns=words_vocab)\n",
    "    OneHot = pd.DataFrame(OneHot,columns=words_vocab)\n",
    "    return TfIdf,OneHot,words_vocab\n",
    "\n",
    "TfIdf,OneHot,words_vocab = build_tfidf(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_vector(query, Vector, words_vocab):\n",
    "    vector_query = np.zeros(len(words_vocab))\n",
    "    #给定用户问题的单词列表query，通过向量表示Vector和词表words_vocab生成用户问题的向量表示vector_query\n",
    "    #######***************************答题区4***************************#######\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #######************************************************************#######\n",
    "    return vector_query\n",
    "                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#句子间距离计算方法\n",
    "def sentences_distance(vec_1, vec_2):\n",
    "    \"\"\"\n",
    "    :return: 两句文本向量的相识度\n",
    "    \"\"\"\n",
    "    #余弦公式 Cosin Distance\n",
    "    #######***************************答题区5***************************#######\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #######************************************************************#######\n",
    "    #欧式距离Euclidean Distance\n",
    "    #######***************************答题区5***************************#######\n",
    "    \n",
    "    \n",
    "    \n",
    "    #######************************************************************#######\n",
    "    #曼哈顿距离Manhattan Distance\n",
    "    #######***************************答题区5***************************#######\n",
    "    \n",
    "    \n",
    "    \n",
    "    #######************************************************************#######\n",
    "    return cos,euc,man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#所有问题组合起来的倒排表 result,格式如下\n",
    "#result={word1:[问题1,问题2,...],word2:[问题1,问题3,...]...}\n",
    "#即记录每个词分别出现在第几个问题中\n",
    "result = {}\n",
    "for i in range(len(corpus)):\n",
    "    idx, words = i, corpus.iloc[i]['cut_review']\n",
    "    for word in words:#words in each candicate questions\n",
    "        if word in result.keys():\n",
    "            result[word].append(idx)\n",
    "        else:\n",
    "            result[word]= [idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过用户问题从问题集合中选出候选问题\n",
    "sentence='电力监控系统中的调度数据网络是什么'\n",
    "clean_reviewyonghu = remove_punctuation(sentence)  # 用户问题去除标点\n",
    "cut_reviewyonghu = [w for w in list(jieba.cut(clean_reviewyonghu)) if\n",
    "                        w not in stopwords and len(w) > 1]  # 用户问题去除停用词，单字词 得到关键词\n",
    "\n",
    "#查找用户问题关键词在数据库中对应的问题id\n",
    "Problem_Id = []\n",
    "for word in cut_reviewyonghu:\n",
    "    if word in result.keys():\n",
    "        Problem_Id.extend(result[word])\n",
    "id = (list(set(Problem_Id)))  # 去重之后的ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算余弦相似度\n",
    "query = sentence  # 用户所提问题\n",
    "similarity_cos = {}  # 存储余弦相似度结果\n",
    "similarity_euc = {}  # 存储欧式距离结果\n",
    "similarity_man = {}  # 存储曼哈顿距离结果\n",
    "if len(id) == 0:\n",
    "    print('数据库里没有该问题，请重新提问')\n",
    "else:\n",
    "    #使用函数cosine_similarity求出与用户问题最相似的问题，排序输出和用户问题相似度最高的前3个问题的答案案\n",
    "    #这里我们采用TfIdf的向量表示\n",
    "#######***************************答题区6***************************#######\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#######************************************************************#######\n",
    "#res_cos,res_euc,res_man分别存放的是排序后的相似问题及相似度分数\n",
    "\n",
    "#打印输出结果\n",
    "print('用户所提的问题是：', query,'\\n')\n",
    "print('********************************************************************')\n",
    "#余弦相似度排名\n",
    "print(\"和用户问题相似度最高的前3个问题:\\n\",res_cos)\n",
    "for i, j in res_cos:\n",
    "    print('数据库相似的问题是:{0} {1} \\n 答案是:{2} \\n 相似度是:{3}\\n'.format(i,corpus.iloc[i]['题干'], corpus.iloc[i]['答案'],j))\n",
    "print('********************************************************************')\n",
    "#欧式距离排名\n",
    "print(\"和用户问题相似度最高的前3个问题:\\n\",res_euc)\n",
    "for i, j in res_euc:\n",
    "     print('数据库相似的问题是:{0} {1} \\n 答案是:{2} \\n 相似度是:{3}\\n'.format(i,corpus.iloc[i]['题干'], corpus.iloc[i]['答案'],j))\n",
    "print('********************************************************************')\n",
    "#曼哈顿距离排名\n",
    "print(\"和用户问题相似度最高的前3个问题:\\n\",res_man)\n",
    "for i, j in res_man:\n",
    "     print('数据库相似的问题是:{0} {1} \\n 答案是:{2} \\n 相似度是:{3}\\n'.format(i,corpus.iloc[i]['题干'], corpus.iloc[i]['答案'],j))\n",
    "print('********************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
